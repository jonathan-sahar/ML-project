__author__ = 'Inspiron'
import os
import csv #TODO make sure doesn't use csv because in featureCalculationFunctions
import re
from constants import *
import numpy as np
from featureCalculationFunctions import *


def aggregate(aggregators, windowType, dataWindow, aggregatedWindows):
    '''

    :param aggregators:
    :param windowType:
    :param dataWindow:
    :param aggregatedWindows:
    :return: headers: the list of headers matching output of all functions in aggregators
    :return: aggregatedWindow: the line of values generated by the aggregators for this time window.
    '''
    headers = []
    aggregatedWindow = np.atleast_2d([])
    for func in aggregators:
        if windowType == 'short':
            header, data = func(dataWindow)
        elif windowType == 'long':
            header, data = func(dataWindow, aggregatedWindows)
        else: #windowType == 'entire'
            header, data = func(dataWindow, aggregatedWindows)
        headers += header
        aggregatedWindow = np.hstack((aggregatedWindow, data))

    return headers, aggregatedWindow

def createTimeWindowTable(aggregatorsList, windowType, dataWindows, aggregatedWindows):
    '''

    :param aggregatorsList: list of functions that reduce the data in a window to a single line
    :param windowType: one of 'short' , 'long', 'entire'
    :param dataWindows: list of (structured) arrays
    :param aggregatedWindows:  list of reduced windows, either short, if windowType is 'long', or long windows if windowType is 'entire'
    :return: a structured array: contains a line for every window in dataWindows.
    '''
    if windowType == 'short':
        header, firstAggregatedWindow = aggregate(aggregatorsList, windowType, dataWindows[0], None)
        table = [firstAggregatedWindow]
        for timeWindow in dataWindows[1:]:
            _, row = aggregate(aggregatorsList, windowType, timeWindow, None)
            table.append(row)
    else:
        if windowType == 'long':
            assert len(dataWindows) == len(aggregatedWindows)
        aggIter = iter(aggregatedWindows)
        header, firstAggregatedWindow = aggregate(aggregatorsList, windowType, dataWindows[0], aggIter.next())
        table = [firstAggregatedWindow]
        for timeWindow in dataWindows:
            item = aggIter.next()
            _, row = aggregate(aggregatorsList, windowType, timeWindow, item)
            table.append(row)
    dt = zip(header, len(header)*['f4']) # TODO: set the field type in a constant. are 4 bytes enough?
    rows = [tuple(list(row[0])) for row in table]
    ret = np.array(rows, dtype=dt)
    return ret


def divideToWindows(dataMatrix, windowLength):
    '''
    :param dataMatrix:
    :param windowLength:
`    :return: windows is a list of arrays
    '''
    return  [dataMatrix[a:a+windowLength] for a in range(len(dataMatrix)-windowLength + 1)]

    # firtsIteration = True
    # if dataMatrix == []:
    #     return []
    # windows =[]
    # window = []
    # lineCounter = 0
    # for row in dataMatrix:
    #     lineCounter +=1
    #     window.append(row)
    #     if firtsIteration == True:
    #         if lineCounter == windowLength+1:
    #             lineCounter = 0
    #             windows.append(window)
    #             window = []
    #             firtsIteration = False
    #     else:
    #         if lineCounter == windowLength:
    #             lineCounter = 0
    #             windows.append(window)
    #             window = []
    # return windows


def readFileToFloat(filePath):
    '''
    Assumes file  contains headers
    :param filePath:
    :return:
    '''
    newFile = open(filePath, 'r')
    data = np.genfromtxt(filePath, dtype=float, delimiter=',', names = True, case_sensitive=True)
    field_names = np.array(data.dtype.names)
    r = re.compile(r'(.*time.*|.*patient.*)',re.IGNORECASE)
    vmatch = np.vectorize(lambda x:bool(r.match(x)))
    mask = ~vmatch(field_names) # mask is true where field name doesn't contain 'time' or 'patient'
    return data[field_names[mask]]


def readFileAsIs(filePath):
    newFile = open(filePath, 'r')
    reader = csv.reader(newFile)
    allLines = [row for row in reader]
    newFile.close()
    return allLines

def createFeatures(outputDir = UNIFIED_TABLES_PATH):
    #define the aggregators for each table
    aggregatorsListLong = []
    aggregatorsListShort = []
    aggregatorsListEntire = []

    #initialize
    dataMatrix = dict()
    labelsMatrix = dict()
    aggregatedSubWindows = dict()
    aggregatedWindows = []

    #create 5 sec per line table, per person
    for patient in PATIENTS_test: # TODO: change back to PATIENTS!
        #read patient data, separate between actual features and labels
        patientData = readFileToFloat(os.path.join(outputDir, "DATAFILE_" + patient + ".csv"))
        names = np.array(patientData.dtype.names)
        labelField = names[np.where((names == 'Is_Sick'))]
        dataFields = names[np.where((names != 'Is_Sick'))]
        patientLabels = patientData[[labelField]]
        patientData = patientData[[dataFields]]

        # insert data into matrix
        labelsMatrix[patient] = patientLabels
        dataMatrix[patient] = patientData

        #divide to windows, and reduce/aggregate every window into a line.
        dataSubWindows = divideToWindows(patientData, SHORT_TIME_WINDOW) # dataSubWindows is a list of structured arrays.
        aggregatedSubWindows[patient] = (createTimeWindowTable(aggregatorsListShort, 'short', dataSubWindows, None)) #TODO check if easy to return the table

        #write to patient file
        shortAggregatedFile = open(SHORT_TABLE_FILE_PATH[:-4]+'_'+patient+'.csv', 'w')
        writer = csv.writer(shortAggregatedFile, lineterminator='\n')
        patientTable = aggregatedSubWindows[patient] # every line is the reduction of a 5 sec window of current patient's data
        writer.writerow(patientTable.dtype.names)
        writer.writerows(patientTable)


    # TODO: change path creation behavior in rest of file to match the above (using outputDir)
    #create 5 min per line table
    assert len(PATIENTS) == len(dataMatrix)
    # for patient, patientData in zip(PATIENTS, dataMatrix):
    for patient, patientData in dataMatrix.items():
        longAggregatedFile = open(LONG_TABLE_FILE_PATH[:-4]+'_'+patient+'.csv', 'w')

        #DATA_LEN/LONG_TIME_WINDOW WINDOWS
        dataWindows = divideToWindows(patientData, LONG_TIME_WINDOW)

        #(DATA_LEN/SHORT_TIME_WINDOW)/(LONG_TIME_WINDOW/SHORT_TIME_WINDOW) WINDOWS = DATA_LEN/LONG_TIME
        subWindows = divideToWindows(aggregatedSubWindows[patient], LONG_TIME_WINDOW/SHORT_TIME_WINDOW)
        aggregatedWindows.append(createTimeWindowTable(aggregatorsListLong, 'long', dataWindows, subWindows))

        writer = csv.writer(longAggregatedFile, lineterminator='\n')
        patientTable = aggregatedSubWindows[patient] # every line is the reduction of a 5 min window of current patient's data
        writer.writerow(patientTable.dtype.names)
        writer.writerows(patientTable)

    #create patient per line table
    #patientWindowsList = divideToPatients(dataMatrix, LongWindowsMatrix) not necesssary any more
    for patient in PATIENTS:
        entireAggregatedFile = open(ENTIRE_TABLE_FILE_PATH[:-4]+'_'+patient+'.csv', 'w')
        unifiedTable = np.vstack(tuple(dataMatrix))
        aggregatedAll = createTimeWindowTable(aggregatorsListEntire, 'entire', unifiedTable, aggregatedWindows)
        writer = csv.writer(entireAggregatedFile, lineterminator='\n')
        writer.writerow(aggregatedAll.dtype.names)
        writer.writerows(aggregatedAll)

if __name__ == "__main__":
    createFeatures()